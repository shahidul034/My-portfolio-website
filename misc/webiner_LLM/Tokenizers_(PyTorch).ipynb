{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMYlizpuW5JF"
      },
      "source": [
        "# Tokenizers (PyTorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qZRjvVQtW5JG",
        "outputId": "3b6bd013-29d9-4e8f-e48d-8eb6ba1696ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Jim', 'Henson', 'was', 'a', 'puppeteer']\n"
          ]
        }
      ],
      "source": [
        "tokenized_text = \"Jim Henson was a puppeteer\".split()\n",
        "print(tokenized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y3BiDaqgW5JH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/mshahidul/miniconda3/envs/web/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YgzAoRRPW5JH"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_Lnq6PUeW5JH",
        "outputId": "64b5f5d3-76ed-4713-cfab-12bde4a50d74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [101, 7993, 170, 13809, 23763, 2443, 1110, 3014, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\"Using a Transformer network is simple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vc8tAkAoW5JH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/home/mshahidul/webiner/tokenizer/tokenizer_config.json',\n",
              " '/home/mshahidul/webiner/tokenizer/special_tokens_map.json',\n",
              " '/home/mshahidul/webiner/tokenizer/vocab.txt',\n",
              " '/home/mshahidul/webiner/tokenizer/added_tokens.json',\n",
              " '/home/mshahidul/webiner/tokenizer/tokenizer.json')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.save_pretrained(\"/home/mshahidul/webiner/tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ND7Tg4UIW5JH",
        "outputId": "f3b405f3-9603-4d88-8984-063b3f3651dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "sequence = \"Using a Transformer network is simple\"\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vQRG2Mv_W5JH",
        "outputId": "2201cf9a-f7ab-4580-d53c-92753935357d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7993, 170, 13809, 23763, 2443, 1110, 3014]\n"
          ]
        }
      ],
      "source": [
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5HfBDwzZW5JH",
        "outputId": "d45251fe-0050-4621-d6a7-59be65641413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using a transformer network is simple\n"
          ]
        }
      ],
      "source": [
        "decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])\n",
        "print(decoded_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPclE0-YXeSr"
      },
      "source": [
        "## Train a tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILAHt3DiXdqE"
      },
      "outputs": [],
      "source": [
        "paragraph='''\n",
        "From that survey, astronomers hope to learn about the birth of our Milky Way galaxy, the mysterious matter comprising much of the cosmos, and how the universe evolved into its current arrangement. Perhaps they will even uncover clues about its fate. They will also use the telescope to home in on millions of transient objects, “faint things that go bang, explode or move in the night,” said Tony Tyson, an astrophysicist at the University of California, Davis. That includes gorging black holes and collisions of dense, dead stars. Smile, universe! It is time for your close-up with the Vera C. Rubin Observatory.\n",
        "\n",
        "The telescope, more than two decades in the making, will provide a comprehensive view of the night sky unlike anything astronomers have seen before. The project’s scientists revealed some of the first imagery it released on Monday.\n",
        "\n",
        "“Rubin Observatory is the greatest astronomical discovery machine ever built,” Željko Ivezić, the director of construction, said during the presentation revealing the first images. He noted that for the first time, the number of observed celestial objects will be greater than the number of people living on Earth.\n",
        "\n",
        "Over the next decade, the imagery will be patched together to create “the greatest movie of all time,” Dr. Ivezić said.\n",
        "\n",
        "The observatory, named after the astronomer Vera Rubin, is a joint venture of the U.S. Department of Energy and the National Science Foundation. It was built on a mountain in northern Chile in the foothills of the Andes at the edge of the Atacama Desert. The location, high and dry, provides clear skies for observing the cosmos.\n",
        "\n",
        "At the news conference on Monday, Dr. Ivezić explained that part of Rubin’s powerful capability was that its singular data set would serve many different science goals.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-gDQSjKYTLz"
      },
      "outputs": [],
      "source": [
        "sentences=paragraph.split('.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6r_3O0hcJju",
        "outputId": "49ee4cfb-02c2-445d-abce-1bbbf2381a2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence'],\n",
              "        num_rows: 20\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prompt: convert sentences into dataset dict\n",
        "\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "data = {\"sentence\": sentences}\n",
        "dataset = Dataset.from_dict(data)\n",
        "\n",
        "raw_datasets = DatasetDict({\"train\": dataset})\n",
        "\n",
        "raw_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGuWt8yyaqXS"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_corpus = [raw_datasets[\"train\"][i: i + 2][\"sentence\"] for i in range(0, len(raw_datasets[\"train\"]), 2)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvUX9ywlX6t4"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "old_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUKmSNnNc7l8"
      },
      "outputs": [],
      "source": [
        "tokenizer = old_tokenizer.train_new_from_iterator(training_corpus, 52000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1MX1Gp_dBnb",
        "outputId": "36ed7f27-35a4-49f5-c9d8-2b5f8fb3968b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Ċ',\n",
              " 'From',\n",
              " 'Ġthat',\n",
              " 'Ġsurvey',\n",
              " ',',\n",
              " 'Ġastronomers',\n",
              " 'Ġhope',\n",
              " 'Ġto',\n",
              " 'Ġlearn',\n",
              " 'Ġabout',\n",
              " 'Ġthe',\n",
              " 'Ġbirth',\n",
              " 'Ġof',\n",
              " 'Ġour',\n",
              " 'ĠMilky',\n",
              " 'ĠWay',\n",
              " 'Ġgalaxy',\n",
              " ',',\n",
              " 'Ġthe',\n",
              " 'Ġmysterious',\n",
              " 'Ġmatter',\n",
              " 'Ġcomprising',\n",
              " 'Ġmuch',\n",
              " 'Ġof',\n",
              " 'Ġthe',\n",
              " 'Ġcosmos',\n",
              " ',',\n",
              " 'Ġand',\n",
              " 'Ġhow',\n",
              " 'Ġthe',\n",
              " 'Ġuniverse',\n",
              " 'Ġevolved',\n",
              " 'Ġinto',\n",
              " 'Ġits',\n",
              " 'Ġcurrent',\n",
              " 'Ġarrangement']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = tokenizer.tokenize(raw_datasets['train']['sentence'][0])\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlnWjaIrdRgg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
